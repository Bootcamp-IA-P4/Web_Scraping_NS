# ğŸš€ Project Web Scraping - Comentarios de Libros ğŸ“š

## Ãndice

1.  [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
2.  [Estructura del Proyecto](#estructura-del-proyecto)
3.  [ğŸ› ï¸ Requisitos](#requisitos)
4.  [âš™ï¸ InstalaciÃ³n](#instalaciÃ³n)
5.  [ğŸ•¹ï¸ Uso](#uso)
6.  [ğŸ§ª Testing](#Testing)
7.  [ğŸ³ Despliegue con Docker](#despliegue-con-docker)
8.  [â¡ï¸ PrÃ³ximos Pasos](#prÃ³ximos-pasos)
9.  [ğŸ¤ ContribuciÃ³n](#contribuciÃ³n)
10. [ğŸ‘©â€ğŸ’» Autora](#Autora)


## DescripciÃ³n del Proyecto

Este proyecto realiza web scraping de comentarios de libros de una web de recomedaciÃ³n de libros utilizando Selenium y Django. Los datos extraÃ­dos se almacenan en una base de datos MongoDB Atlas y se visualizan a travÃ©s de una interfaz interactiva creada con Streamlit.

## Estructura del Proyecto
* project_webScraping/
    * .webscraper.log
    * db.sqlite3
    * Dockerfile
    * docker-compose.yml
    * manage.py
    * project_webScraping/
        * settings.py
        * urls.py
    * scraper/
        * models.py
        * tests.py
        * front/
            * app.py
        * migrations/
        * services/
            * book_scraper.py* project_webScraping/

    
## ğŸ› ï¸ Requisitos

* Python 3.8+
* Django
* Selenium
* Streamlit
* MongoDB Atlas
* ChromeDriver
* Docker

## âš™ï¸ InstalaciÃ³n

1.  Clonar el repositorio:

    ```bash
    git clone https://github.com/Bootcamp-IA-P4/Web_Scraping_NS.git
    cd project_webScraping
    ```

2.  Crear y activar un entorno virtual:

    ```bash
    python -m venv .venv
    source .venv\Scripts\activate  # En Windows
    ```

3.  Instalar dependencias:

    ```bash
    pip install -r requirements.txt
    ```

4.  Configurar Django:

    * Asegurar que `settings.py` estÃ© configurado con la conexiÃ³n a MongoDB Atlas.
    * Ejecutar las migraciones:

        ```bash
        python manage.py makemigrations
        python manage.py migrate
        ```

5.  Ejecutar el proyecto:

    * Ejecutar la aplicaciÃ³n Streamlit a la altura de manage.py:

        ```bash
        streamlit run scrape/front/app.py
        ```

## ğŸ•¹ï¸ Uso

1.  Se abre la web con los comentarios anteriores y el scraper se ejecuta al pulsar en iniciar y guarda los comentarios en MongoDB Atlas.

## ğŸ§ª Testing

Incluye testing:

Para probar los tests:

1. Activar el entorno virtual.
2. Ejecutar el siguiente comando:

    ```bash
    python manage.py test
    ```
<div align="center">
  <img src="https://res.cloudinary.com/artevivo/image/upload/v1742771260/Captura_de_pantalla_2025-03-24_000718_fc4zwc.png" width="700" alt="Art Brushes" />
</div>

## ğŸ³ Despliegue con Docker

Este proyecto puede ser fÃ¡cilmente desplegado utilizando Docker Compose.

1.  **Archivo `Dockerfile` y `docker-compose.yml`:** Ya existen los archivos `Dockerfile` y `docker-compose.yml` en la raÃ­z del proyecto. Estos archivos contienen la configuraciÃ³n necesaria para construir y orquestar los contenedores de la aplicaciÃ³n.

2.  **Levantar la aplicaciÃ³n con Docker Compose:**

    Para construir la imagen e iniciar los contenedores definidos en `docker-compose.yml`, ejecuta el siguiente comando en la raÃ­z del proyecto:

    ```bash
    docker-compose up --build 
    ```

    La aplicaciÃ³n estarÃ¡ accesible en  `http://localhost:8501` para Streamlit.

    Para ver los logs de los contenedores:

    Para detener los contenedores:

    ```bash
    docker-compose down
    ```



## â¡ï¸ PrÃ³ximos Pasos

* Implementar autenticaciÃ³n de usuario.
* AÃ±adir mÃ¡s filtros y opciones de bÃºsqueda en la interfaz de Streamlit.
* Optimizar el rendimiento del scraper.


## ğŸ¤ ContribuciÃ³n

Si deseas contribuir a este proyecto, sigue estos pasos:

1.  Haz un fork del repositorio.
2.  Crea una rama con tu funcionalidad (`git checkout -b feature/nueva-funcionalidad`).
3.  Realiza los cambios y commitea (`git commit -am 'AÃ±ade nueva funcionalidad'`).
4.  Sube los cambios a tu rama (`git push origin feature/nueva-funcionalidad`).
5.  Abre un pull request.

## ğŸ‘©â€ğŸ’» Autora

*   [Nhoeli Salazar](https://github.com/Nho89)
